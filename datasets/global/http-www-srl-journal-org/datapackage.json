{
  "license_title": "Other (Open)",
  "maintainer": "",
  "relationships_as_object": [],
  "private": false,
  "maintainer_email": "",
  "num_tags": 1,
  "id": "bebe12a4-606c-4c91-85b5-c0f82646c85b",
  "metadata_created": "2013-07-16T06:46:26.596015",
  "metadata_modified": "2013-10-10T21:17:42.073498",
  "author": "",
  "author_email": "",
  "state": "active",
  "version": null,
  "creator_user_id": "20e0514b-d58d-42af-bf15-5fbe7e00ffdc",
  "type": "dataset",
  "resources": [
    {
      "mimetype": null,
      "cache_url": null,
      "hash": "",
      "description": "The Generalized Pareto model is considered underlying model from which observables are to be predicted by Bayesian approach. The Typeâ€“II censored data from the model is considered for the Central Coverage Bayes prediction technique. Both the known and unknown cases of the parameters have been considered here. A simulation study also has been carried out for illustrating the performances of the procedures.",
      "name": "Central Coverage Bayes Prediction Intervals for the Generalized Pareto Distribution",
      "format": "",
      "url": "http://www.srl-journal.org/paperInfo.aspx?ID=5613",
      "datastore_active": false,
      "cache_last_updated": null,
      "package_id": "bebe12a4-606c-4c91-85b5-c0f82646c85b",
      "created": "2013-07-16T01:47:00.344653",
      "state": "active",
      "mimetype_inner": null,
      "last_modified": null,
      "position": 0,
      "revision_id": "c1109ae5-1553-4bfc-a268-520ca86fac5e",
      "url_type": null,
      "id": "554e4983-65a3-4a49-b4b5-c1e338622733",
      "resource_type": "file",
      "size": null
    },
    {
      "mimetype": null,
      "cache_url": null,
      "hash": "",
      "description": " Nuclear material accounting (NMA) is a component of nuclear safeguards, which are designed to deter and detect illicit diversion of special nuclear material (SNM) from the peaceful fuel cycle to a weapons program. NMA consists of periodically, but at relatively low frequency, comparing measured SNM inputs to measured SNM outputs, and adjusting for measured changes in inventory. Process monitoring (PM) is a relatively recent component of safeguards that consists of data more frequently collected than NMA data. PM data are often only an indirect measurement of the SNM and is typically used as a qualitative measure to supplement NMA, or to support indirect estimation of difficult-to-measure inventory for NMA. This paper introduces quantitative diversion detection options for NMA and PM data, which can be regarded as time series of residuals. Unique statistical challenges in combining NMA and PM residual time series include: PM and NMA data are collected at different frequencies; PM residuals often have a probability distribution that cannot be adequately modeled by a Gaussian distribution, not all PM and NMA data streams are independent, and the monitoring scheme must have reasonably high detection probability for both abrupt and protracted diversion.",
      "name": "Pattern Recognition Options to Combine Process Monitoring and Material Accounting Data in Nuclear Safeguards",
      "format": "",
      "url": "http://www.srl-journal.org/paperInfo.aspx?ID=5617",
      "datastore_active": false,
      "cache_last_updated": null,
      "package_id": "bebe12a4-606c-4c91-85b5-c0f82646c85b",
      "created": "2013-07-16T01:47:52.911525",
      "state": "active",
      "mimetype_inner": null,
      "last_modified": null,
      "position": 1,
      "revision_id": "b6fd8afe-7362-490e-9c8a-632ecd4710e1",
      "url_type": null,
      "id": "4f1fdab8-2ea6-4134-ae26-1f4718e0890b",
      "resource_type": "file",
      "size": null
    },
    {
      "mimetype": null,
      "cache_url": null,
      "hash": "",
      "description": "One of the difficulties in analyzing accelerated life testing data is the model-based failure probability prediction. Choosing an inferior model yields inaccurate predictions that can be exaggerated by extrapolation. Furthermore, testing data are often naturally clustered in groups, thus some modeling exibility must be granted to handle both the intra-cluster and inter-cluster variations. To address these problems, we discuss a data fitting strategy in this paper by developing a semiparametric model with random effects and the Bayesian piecewise exponential inference method. The proportional hazard model and Weibull accelerated failure time model are examined and compared. Our result suggests that the Bayesian piecewise exponential model with random effects outperforms other models.\r\n",
      "name": "Semiparametric Model and Bayesian Analysis for Clustered Accelerated Life Testing Data",
      "format": "",
      "url": "http://www.srl-journal.org/paperInfo.aspx?ID=5614",
      "datastore_active": false,
      "cache_last_updated": null,
      "package_id": "bebe12a4-606c-4c91-85b5-c0f82646c85b",
      "created": "2013-07-16T01:48:34.517838",
      "state": "active",
      "mimetype_inner": null,
      "last_modified": null,
      "position": 2,
      "revision_id": "d191f22e-f708-4e46-8c46-acaa7e491745",
      "url_type": null,
      "id": "83e41711-aa19-4c48-9f98-a37f73420c79",
      "resource_type": "file",
      "size": null
    },
    {
      "mimetype": null,
      "cache_url": null,
      "hash": "",
      "description": "Waterflooding is among the oldest and perhaps the most economical of oil recovery processes to extend field life and increase ultimate oil recovery from naturally depleting reservoirs. During waterflood operations, water is injected into the reservoir to maintain a certain reservoir pressure as well as to push the oil in the reservoir towards the producing wells. Nowadays, any organization always has to strive for lean and efficient technologies and processes to maximize profit also when looking deeper into their reservoir portfolios in order to identify additional waterflooding opportunities. Time and information constraints can limit the depth and rigor of such a screening evaluation. Time is reflected by the effort of screening a vast number of reservoirs for the applicability of implementing a waterflood, whereas information is reflected by the availability and quality of data (consistency of measured and modeled data with the inherent rules of a petroleum system) with which to extract significant knowledge necessary to make good development decisions. A new approach to screening a large number of reservoirs uses a wide variety of input information and satisfies a number of constraints such as physical, financial, geopolitical, and human constraints. In a fully stochastic workflow that includes stochastic back-population of incomplete datasets, stochastic proxy models over time series, and stochastic ranking methods using Bayesian belief networks, more than 1,500 reservoirs were screened for additional recovery potential with waterflooding operations. The objective of the screening process is to reduce the number of reservoirs by one order of magnitude to about 100 potential candidates that are suitable for a more detailed evaluation. Numerical models were used to create response surfaces as surrogate reservoir models that capture the sensitivity and uncertainty of the influencing input parameters on the output. Reservoir uncertainties were combined with expert knowledge and environmental variables and were used as proxy model states in the formulation of objective functions. The input parameters were initiated and processed in a stochastic manner throughout the presented work. The output is represented by a ranking of potential waterflood candidates. The benefit of this approach is the inclusion of a wide range of influencing parameters while at the same time speeding up the screening process without jeopardizing the quality of the results.",
      "name": "Screening of a Probabilistic Database Using Stochastic Reasoning Driven by Surrogate Models",
      "format": "",
      "url": "http://www.srl-journal.org/paperInfo.aspx?ID=5618",
      "datastore_active": false,
      "cache_last_updated": null,
      "package_id": "bebe12a4-606c-4c91-85b5-c0f82646c85b",
      "created": "2013-07-16T01:49:08.945515",
      "state": "active",
      "mimetype_inner": null,
      "last_modified": null,
      "position": 3,
      "revision_id": "65c8adaf-ca0c-4779-9332-01c667a3b98f",
      "url_type": null,
      "id": "e6506ea5-d0fd-45b6-9f9f-e5a1add23423",
      "resource_type": "file",
      "size": null
    },
    {
      "mimetype": null,
      "cache_url": null,
      "hash": "",
      "description": "This paper is concerned with the auto-covariance function (ACVF) of a regime switching AR (1) process. In this model, two independent Markov chains govern on auto-regressive coefficient and standard deviation of white noise process. Our approach to solve this problem is to obtain the ACVF of a AR(1) model with time varying parameters and then to extend this result to regime switching case. An application of our formulae in model selection is proposed. Finally, a conclusion section is also given.",
      "name": "A Note on Covariance Function of a Regime Switching AR (1) Process",
      "format": "",
      "url": "http://www.srl-journal.org/paperInfo.aspx?ID=5611",
      "datastore_active": false,
      "cache_last_updated": null,
      "package_id": "bebe12a4-606c-4c91-85b5-c0f82646c85b",
      "created": "2013-07-16T01:49:44.667289",
      "state": "active",
      "mimetype_inner": null,
      "last_modified": null,
      "position": 4,
      "revision_id": "969607bc-b8bf-427a-bc44-894cb7e0fb22",
      "url_type": null,
      "id": "dcafeff7-63a2-49d3-9169-d91227765a8b",
      "resource_type": "file",
      "size": null
    },
    {
      "mimetype": null,
      "cache_url": null,
      "hash": "",
      "description": " The validity of statistical analyses applied to identify different factors in many fields depends upon the use of appropriate sample sizes, the lack of which reduces the power of the findings. However, the number of cases collected for data analysis in medical studies is generally limited, for medical, financial and other experimental reasons, and statistical tests are often carried out without power and sample size estimation. Power analysis involvesseveral parameters, the most importantof which, the effect size, reflects the degree of the effect expected to be found in the study. An easy-to-use MS Excel calculator has been constructedto determine the effect size forchi-square tests based on 2Ã—2, 2Ã—3 and 2Ã—4 contingency tables,and compared the results obtained with this calculatorwith those given byGPower, R and,for a 2Ã—2 table,SAS softwaretodemonstrate the practical use of this calculation tool in three studies involving various data.",
      "name": "Effect Size Calculation in Power Estimation for the Chi-square Test of Preliminary Data in Different Studies",
      "format": "",
      "url": "http://www.srl-journal.org/paperInfo.aspx?ID=5624",
      "datastore_active": false,
      "cache_last_updated": null,
      "package_id": "bebe12a4-606c-4c91-85b5-c0f82646c85b",
      "created": "2013-07-16T01:50:22.516033",
      "state": "active",
      "mimetype_inner": null,
      "last_modified": null,
      "position": 5,
      "revision_id": "e42c0b08-2253-4cf3-933e-09a0840fa0b6",
      "url_type": null,
      "id": "2d50582c-c381-4138-b75d-6190c5d37476",
      "resource_type": "file",
      "size": null
    },
    {
      "mimetype": null,
      "cache_url": null,
      "hash": "",
      "description": "This paper extends the cure rate model considered in Lopes and Bolfarine (2012) by taking into account random effects in both, the probability of cure and the survival function for individuals that are at risk. The model is parametrized in terms of the cured fraction which is then linked to covariates. The estimation is based on the restricted maximum likelihood (REML) approach proposed in McGilchrist and Yau (1995). Simulation studies are performed and results based on a real data set are presented indicating good performance of the proposed approach.\r\n",
      "name": "Promotion Time Cure Rate Model with Random Effects: an Application to a Multi-centre Clinical Trial of Carcinoma",
      "format": "",
      "url": "http://www.srl-journal.org/paperInfo.aspx?ID=5615",
      "datastore_active": false,
      "cache_last_updated": null,
      "package_id": "bebe12a4-606c-4c91-85b5-c0f82646c85b",
      "created": "2013-07-16T01:50:53.401882",
      "state": "active",
      "mimetype_inner": null,
      "last_modified": null,
      "position": 6,
      "revision_id": "e0ed8b88-8fd8-472d-ad04-4e77292d0731",
      "url_type": null,
      "id": "cbcc8d6e-f30e-48c5-9da4-e392183e7d6d",
      "resource_type": "file",
      "size": null
    },
    {
      "mimetype": null,
      "cache_url": null,
      "hash": "",
      "description": "The object of this paper is a Bayesian analysis of the autoregressive model X_t = Î²_1 X_(t-1)+Îµ_t ,t=1,..,m and X_t = Î²_2 X_(t-1)+Îµ_t ,t=m+1,..,n where 0 < Î²_1,Î²_2 < 1, and Îµ_t is independent random variable with an exponential distribution with mean Î¸_1 but later it was found that there was a change in the process at some point of time m which is reflected in the sequence after Îµ_(m )is changed in mean Î¸_2. The issue this study focused on is at what time and which point the change begins to occur. The estimators of m, Î²_1 ã€–,Î²ã€—_2 and Î¸_1,Î¸_2are derived from Asymmetric loss functions namely Linex loss & General Entropy loss functions. Both the non-informative and informative priors are considered. The effects of prior consideration on Bayes estimates of change point are also studied.\r\n",
      "name": "Bayesian Estimation of AR (1) with Change Point under Asymmetric Loss Functions",
      "format": "",
      "url": "http://www.srl-journal.org/paperInfo.aspx?ID=5616",
      "datastore_active": false,
      "cache_last_updated": null,
      "package_id": "bebe12a4-606c-4c91-85b5-c0f82646c85b",
      "created": "2013-07-16T01:51:44.018180",
      "state": "active",
      "mimetype_inner": null,
      "last_modified": null,
      "position": 7,
      "revision_id": "d495639e-9fa0-4697-bcb6-3794b09231b2",
      "url_type": null,
      "id": "f8c0b651-ed3b-4feb-98bf-e70a03f4f9c2",
      "resource_type": "file",
      "size": null
    }
  ],
  "num_resources": 8,
  "tags": [
    {
      "vocabulary_id": null,
      "state": "active",
      "display_name": "Statistics Research",
      "id": "b6f7dd5d-d1fa-408f-afd5-22a525692f96",
      "name": "Statistics Research"
    }
  ],
  "groups": [],
  "license_id": "other-open",
  "relationships_as_subject": [],
  "organization": {
    "description": "",
    "created": "2013-10-10T14:24:46.556146",
    "title": "Global",
    "name": "global",
    "is_organization": true,
    "state": "active",
    "image_url": "",
    "revision_id": "6f9b4b38-6781-489c-bb4d-ea106ee7ac37",
    "type": "organization",
    "id": "94d03217-717d-41ce-a20c-00e754e94183",
    "approval_status": "approved"
  },
  "name": "http-www-srl-journal-org",
  "isopen": true,
  "url": null,
  "notes": "Statistics Research Letters (SRL) is an international open-access and refereed journal dedicated to publishing the latest advancements in statistics research. The goal of this journal is to record the latest findings and promote further research in these areas. Scholars from all relevant academic fields are invited to submit high-quality manuscripts that describe the latest, state-of-the-art research results or innovations.",
  "owner_org": "94d03217-717d-41ce-a20c-00e754e94183",
  "extras": [],
  "title": "Statistics Research Letters (SRL)",
  "revision_id": "54bfd1e6-3ed1-46c3-8b7a-104b0796a4f1"
}